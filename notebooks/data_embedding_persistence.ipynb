{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94828b20",
   "metadata": {},
   "source": [
    "## Data Embedding and Storing to Chroma vector database as persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12103ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eee35d",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#3f79ffff; margin:0; font-weight:600;\">First I am setting up the clients that I need (OpenAI for embedding and Chroma for persistence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading env vars\n",
    "load_dotenv()\n",
    "\n",
    "# setup clients\n",
    "client = OpenAI()\n",
    "chroma_client = chromadb.PersistentClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ad999",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#3f79ffff; margin:0; font-weight:600;\">Loading our previously made CSV with our cleaned data and creating a collection in our ChromaDB where we will store our embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172d8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSV\n",
    "df = pd.read_csv(\"../data/phone_transcripts_v0.1_chunks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2766a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create collection\n",
    "collection = chroma_client.get_or_create_collection(\"phone_transcripts_v0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece1616",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#3f79ffff; margin:0; font-weight:600;\">Looping through all our csv rows and creating the embeddings with the OpenAi \"text-embedding-3-large\" model, within the loop I add the transcripts to the ChromaDB collection and add the other columns as metadata which will help with more advanced searches later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1387952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All chunks saved in Chroma\n"
     ]
    }
   ],
   "source": [
    "# loop through df & create embeddings\n",
    "for _, row in df.iterrows():\n",
    "    text = row[\"transcript\"]\n",
    "    metadata = {\n",
    "        \"call_id\": str(row[\"call_id\"]),\n",
    "        \"date\": str(row[\"date\"]),\n",
    "        \"duration\": str(row[\"duration\"]),\n",
    "        \"speaker\": row[\"speaker\"]\n",
    "    }\n",
    "\n",
    "    # create embedding with OpenAI\n",
    "    emb = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=text\n",
    "    ).data[0].embedding\n",
    "\n",
    "    # save to Chroma\n",
    "    collection.add(\n",
    "        ids=[row[\"chunk_id\"]],\n",
    "        embeddings=[emb],\n",
    "        documents=[text],\n",
    "        metadatas=[metadata]\n",
    "    )\n",
    "\n",
    "print(\"All chunks saved in Chroma\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
